{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "integrated-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(\"..\",\"data\",\"raw\",\"MOT17\",\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worth-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders =  sorted([folder_name \n",
    "                  for folder_name in os.listdir(train_data_path)\n",
    "                  if \"FRCNN\" in folder_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stone-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths ={}\n",
    "for folder_name in train_folders:\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(os.path.join(train_data_path,folder_name,\"seqinfo.ini\"))\n",
    "    sequence_lengths[folder_name] = int(config[\"Sequence\"][\"seqLength\"])\n",
    "video_indices = np.argsort(train_folders)\n",
    "sequence_lengths = torch.Tensor(list(zip(video_indices,list(sequence_lengths.values())))).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "composed-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "frames_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sublime-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_video_indices = torch.randint(len(sequence_lengths)-1,(batch_size,)) # get random video to extract frames\n",
    "random_sequence_lengths = sequence_lengths[random_video_indices] - torch.tensor([0,frames_size]) # get total frames for videos and subtract frame size\n",
    "randomizer = torch.vstack((torch.ones(batch_size),torch.rand(batch_size))).T # create randomizer for size of batch\n",
    "random_start_timestamps = (randomizer*random_sequence_lengths).to(torch.int32) # generate random start time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "functional-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_list = []\n",
    "for i,folder in enumerate(train_folders):\n",
    "    df = pd.read_csv(os.path.join(train_data_path, train_folders[i],\"gt\",\"gt.txt\"),header=None)\n",
    "    df.columns = [\"frame\", \"id\", \"bb_left\", \"bb_top\", \"bb_width\", \"bb_height\", \"x\", \"y\", \"z\"]\n",
    "    df[\"video_id\"] = i\n",
    "    df.drop([\"x\",\"y\",\"z\"],1,inplace=True)\n",
    "    ground_truth_list.append(df)\n",
    "ground_truth_df = pd.concat(ground_truth_list)  \n",
    "ground_truth = torch.tensor(ground_truth_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fatal-finance",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-036af73e54c4>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-036af73e54c4>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    detection_with_batch_idx =\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "detection_batch = []\n",
    "for i,time_stamp in enumerate(random_start_timestamps):\n",
    "    detections=ground_truth[torch.where((ground_truth[:,-1]==time_stamp[0]) & \n",
    "                               (ground_truth[:,0]>time_stamp[1]) & \n",
    "                               (ground_truth[:,0]< time_stamp[1]+frames_size))]\n",
    "    detection_with_batch_idx = \n",
    "    torch.ones((detections.shape[0],detections.shape[1]+1))*i\n",
    "    detection_with_batch_idx[:,:-1] = detections\n",
    "    detection_batch.append(detection_with_batch_idx.to(torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "defensive-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_video_index= torch.randint(len(sequence_lengths)-1,(1,)) # get random video to extract frames\n",
    "random_sequence_lengths = sequence_lengths[random_video_indices] - torch.tensor([0,frames_size]) # get total frames for videos and subtract frame size\n",
    "randomizer = torch.vstack((torch.ones(batch_size),torch.rand(batch_size))).T # create randomizer for size of batch\n",
    "random_start_timestamps = (randomizer*random_sequence_lengths).to(torch.int32) # generate random start time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "least-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4, 654]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_lengths[random_video_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "noble-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_video_index = torch.randint(len(sequence_lengths)-1,(1,)) # get random video to extract frames\n",
    "sequence_length = sequence_lengths[random_video_index]\n",
    "random_start = torch.Tensor([sequence_length[0][0],torch.randint(sequence_length[0][1],(1,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "superior-conviction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2., 687.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,time_stamp in enumerate(random_start_timestamps):\n",
    "    detections=ground_truth[torch.where((ground_truth[:,-1]==time_stamp[0]) & \n",
    "                               (ground_truth[:,0]>time_stamp[1]) & \n",
    "                               (ground_truth[:,0]< time_stamp[1]+frames_size))]\n",
    "    detection_with_batch_idx = \n",
    "    torch.ones((detections.shape[0],detections.shape[1]+1))*i\n",
    "    detection_with_batch_idx[:,:-1] = detections\n",
    "    detection_batch.append(detection_with_batch_idx.to(torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "female-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ground_truth[torch.where((ground_truth[:,-1]==random_start[0]) & \n",
    "                               (ground_truth[:,0]>=random_start[1]) & \n",
    "                               (ground_truth[:,0]< random_start[1]+frames_size))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "musical-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_detections_in_frame = torch.unique(a[:,0],return_counts=True)[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "lyric-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = torch.stack(torch.unique(a[:,0],return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "alternate-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts[:,1] = unique_counts[:,1].max()-unique_counts[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "overhead-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_detections = torch.repeat_interleave(unique_counts[:,0],unique_counts[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "hidden-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_detections_filler  =torch.zeros((missing_detections.shape[0],7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "resident-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_detections_filler[:,0] = missing_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "manual-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_detections_filler[:,1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "intimate-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_detections_filler[:,-1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "special-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_from_frames = torch.vstack([a,missing_detections_filler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-individual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
